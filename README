<div align="center">

# ğŸ¤– RAG Document Chatbot  
### Retrieval-Augmented Generation with LangChain & OpenAI

[![Python](https://img.shields.io/badge/Python-3.9%2B-blue.svg)]
[![Streamlit](https://img.shields.io/badge/Streamlit-App-red.svg)]
[![LangChain](https://img.shields.io/badge/LangChain-RAG-green.svg)]
[![ChromaDB](https://img.shields.io/badge/VectorDB-Chroma-purple.svg)]
[![Status](https://img.shields.io/badge/Status-Interview%20Ready-success.svg)]

A clean, production-aware implementation of a **Retrieval-Augmented Generation (RAG)** system  
that allows users to **chat with their own documents**.

</div>

---

## âœ¨ Overview

Large Language Models are powerful but can hallucinate when they lack context.  
This project solves that problem using **Retrieval-Augmented Generation (RAG)**.

Users upload documents, and the system retrieves the most relevant content  
before generating responses â€” ensuring **accurate, grounded answers**.

---

## ğŸ§  RAG Architecture

```text
User Question
      â†“
Vector Search (ChromaDB)
      â†“
Relevant Document Chunks
      â†“
LLM (OpenAI)
      â†“
Final Answer + Source Documents

ğŸš€ Features

ğŸ“„ Upload documents (PDF, TXT, DOCX, CSV)

âœ‚ï¸ Intelligent text chunking

ğŸ§  Semantic embeddings using OpenAI

ğŸ” Fast vector similarity search with ChromaDB

ğŸ’¬ Conversational chat with memory

ğŸ“Œ Transparent answers with source references

ğŸ¯ Simple, interview-ready design

## ğŸ›  Tech Stack
Layer	Technology
Language	Python
UI	Streamlit
RAG Framework	LangChain
Vector Database	ChromaDB
LLM & Embeddings	OpenAI

ğŸ“‚ Project Structure

RAG_chatbot/
â”‚
â”œâ”€â”€ RAG_app.py
â”œâ”€â”€ README.md
â”œâ”€â”€ requirements.txt
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ tmp/              # Temporary uploaded files
â”‚   â””â”€â”€ vector_store/     # Generated at runtime (gitignored)
â”‚
â””â”€â”€ .gitignore

## â–¶ï¸ Getting Started

1ï¸âƒ£ Install Dependencies
pip install -r requirements.txt

2ï¸âƒ£ Run the Application
streamlit run RAG_app.py

3ï¸âƒ£ Use the Chatbot

1. Enter your OpenAI API key

2. Upload one or more documents

3. Create the vector store

4. Ask questions about your data

## ğŸ” Security & Best Practices

API keys are entered at runtime and never stored

Vector databases are generated dynamically

.env, temporary files, and vector stores are excluded from Git

No pre-built embeddings are committed

## ğŸ¯ Design Philosophy

Focus on core RAG concepts, not demo overload

One LLM provider for clarity and explainability

Simple retriever strategy for reliability

Code that is easy to explain and defend in interviews

## ğŸ“š Learning Outcomes

This project demonstrates:

Practical understanding of Retrieval-Augmented Generation

How vector search grounds LLM responses

Trade-offs in chunk size and retrieval depth

Conversational memory management

Building real-world LLM applications responsibly

## ğŸ“ Note on Authorship

This project is inspired by publicly available RAG examples and official documentation.
The implementation has been refactored, simplified, and structured to clearly demonstrate
understanding of RAG fundamentals and production-aware design.

<div align="center">
â­ If you find this project useful, feel free to star the repository.
</div> ```
